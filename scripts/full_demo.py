#!/usr/bin/env python3
"""
ELF Automations Full System Demo

Comprehensive demonstration of the Virtual AI Company Platform with:
- Real LLM integration (Anthropic Claude)
- Database connectivity (PostgreSQL)
- MCP server functionality
- Agent orchestration
- API server endpoints
"""

import asyncio
import json
import os
import sys
from pathlib import Path

# Add project root to Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import structlog
from dotenv import load_dotenv

from agents.executive.chief_ai_agent import ChiefAIAgent
from agents.registry import AgentRegistry
from mcp_servers.business_tools import BusinessToolsServer

# Configure logging
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.dev.ConsoleRenderer(),
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger(__name__)


async def demo_llm_powered_strategic_planning():
    """Demonstrate LLM-powered strategic planning with real business context."""
    logger.info("üß† Demo: LLM-Powered Strategic Planning")
    logger.info("=" * 50)

    # Create Chief AI Agent
    chief = ChiefAIAgent()
    await chief.start()

    # Real business scenario for strategic planning
    business_context = {
        "company_overview": {
            "name": "ELF Automations",
            "industry": "AI Agent Platforms",
            "stage": "Early Growth",
            "team_size": 15,
            "monthly_revenue": 125000,
        },
        "current_challenges": [
            "Scaling agent deployment infrastructure",
            "Improving inter-agent communication latency",
            "Expanding MCP server ecosystem",
            "Customer onboarding automation",
        ],
        "market_opportunities": [
            "Enterprise AI adoption acceleration",
            "Multi-agent workflow automation",
            "Industry-specific agent templates",
            "Agent marketplace platform",
        ],
        "resources": {
            "engineering_team": 8,
            "sales_team": 3,
            "marketing_budget": 25000,
            "infrastructure_budget": 15000,
        },
    }

    # Ask Chief AI Agent for strategic analysis
    strategic_prompt = f"""
    As the Chief AI Agent of ELF Automations, analyze our current business situation and provide strategic recommendations.

    Business Context:
    {json.dumps(business_context, indent=2)}

    Please provide:
    1. Top 3 strategic priorities for the next quarter
    2. Resource allocation recommendations
    3. Key metrics to track
    4. Risk mitigation strategies
    5. Specific action items with timelines

    Focus on practical, actionable insights that can drive growth and operational efficiency.
    """

    logger.info("Requesting strategic analysis from Chief AI Agent...")

    try:
        strategic_analysis = await chief.think(strategic_prompt)

        logger.info("Strategic Analysis Complete")
        logger.info("=" * 30)
        logger.info(strategic_analysis)

        # Save analysis to file for reference
        analysis_file = project_root / "strategic_analysis.md"
        with open(analysis_file, "w") as f:
            f.write(f"# ELF Automations Strategic Analysis\n\n")
            f.write(f"Generated by Chief AI Agent\n\n")
            f.write(
                f"## Business Context\n\n```json\n{json.dumps(business_context, indent=2)}\n```\n\n"
            )
            f.write(f"## Strategic Analysis\n\n{strategic_analysis}\n")

        logger.info(f"Strategic analysis saved to {analysis_file}")

    except Exception as e:
        logger.error("Strategic planning failed", error=str(e))

    await chief.stop()


async def demo_mcp_business_intelligence():
    """Demonstrate MCP server providing business intelligence."""
    logger.info("üìä Demo: MCP Business Intelligence")
    logger.info("=" * 50)

    # Start MCP server
    mcp_server = BusinessToolsServer()
    await mcp_server.start()

    logger.info("Business Tools MCP Server started")

    try:
        # Get current business metrics
        logger.info("Retrieving current business metrics...")

        financial_metrics = await mcp_server.call_tool(
            "get_business_metrics", {"metric_type": "financial"}
        )
        operational_metrics = await mcp_server.call_tool(
            "get_business_metrics", {"metric_type": "operational"}
        )

        logger.info("Financial Metrics", data=financial_metrics)
        logger.info("Operational Metrics", data=operational_metrics)

        # Get customer data
        logger.info("Retrieving customer data...")
        customers_data = await mcp_server.read_resource("business://customers")
        logger.info(
            "Customer Data Retrieved", preview=str(customers_data)[:200] + "..."
        )

        # Get active tasks
        logger.info("Retrieving active tasks...")
        tasks_data = await mcp_server.read_resource("business://tasks")
        logger.info("Tasks Data Retrieved", preview=str(tasks_data)[:200] + "...")

        # Create a new lead
        logger.info("Creating new lead...")
        new_lead = await mcp_server.call_tool(
            "create_lead",
            {
                "name": "AI Corp Prospect",
                "email": "contact@aicorp.example",
                "company": "AI Corp",
                "source": "demo",
                "notes": "Interested in multi-agent automation platform",
            },
        )
        logger.info("New lead created", result=new_lead)

        # Score the lead
        if isinstance(new_lead, dict) and "id" in new_lead:
            logger.info("Scoring new lead...")
            lead_score = await mcp_server.call_tool(
                "score_lead", {"lead_id": new_lead["id"], "score": 85}
            )
            logger.info("Lead scored", result=lead_score)

    except Exception as e:
        logger.error("MCP business intelligence demo failed", error=str(e))

    await mcp_server.stop()
    logger.info("MCP Server stopped")


async def demo_agent_coordination():
    """Demonstrate agent coordination and task delegation."""
    logger.info("ü§ù Demo: Agent Coordination")
    logger.info("=" * 50)

    # Start Chief AI Agent
    chief = ChiefAIAgent()
    await chief.start()

    # Start MCP server for business context
    mcp_server = BusinessToolsServer()
    await mcp_server.start()

    try:
        # Chief AI Agent analyzes business data and creates coordination plan
        coordination_prompt = """
        As Chief AI Agent, analyze the current business situation and create a coordination plan for our agent team.

        Consider:
        1. Current customer pipeline and sales tasks
        2. Operational efficiency metrics
        3. Resource allocation needs
        4. Priority task assignments

        Provide specific task assignments and coordination strategies for different agent types:
        - Sales agents
        - Marketing agents
        - Operations agents
        - Customer success agents

        Include success metrics and coordination protocols.
        """

        logger.info("Chief AI Agent creating coordination plan...")
        coordination_plan = await chief.think(coordination_prompt)

        logger.info("Agent Coordination Plan")
        logger.info("=" * 30)
        logger.info(coordination_plan)

        # Simulate task creation based on coordination plan
        logger.info("Creating tasks based on coordination plan...")

        coordination_tasks = [
            {
                "title": "Follow up with AI Corp Prospect",
                "description": "Schedule demo call and send product information",
                "assignee": "sales-agent-001",
                "priority": "high",
            },
            {
                "title": "Update marketing automation workflows",
                "description": "Optimize lead scoring and nurturing sequences",
                "assignee": "marketing-agent-001",
                "priority": "medium",
            },
            {
                "title": "Monitor system performance metrics",
                "description": "Track agent response times and task completion rates",
                "assignee": "ops-agent-001",
                "priority": "medium",
            },
        ]

        for task in coordination_tasks:
            try:
                result = await mcp_server.call_tool("create_task", task)
                logger.info(
                    "Task created",
                    task=task["title"],
                    assignee=task["assignee"],
                    result=result,
                )
            except Exception as e:
                logger.error("Failed to create task", task=task["title"], error=str(e))

        # Show registry stats
        stats = AgentRegistry.get_registry_stats()
        logger.info("Agent Registry Stats", stats=stats)

    except Exception as e:
        logger.error("Agent coordination demo failed", error=str(e))

    await chief.stop()
    await mcp_server.stop()


async def demo_performance_monitoring():
    """Demonstrate performance monitoring and optimization."""
    logger.info("üìà Demo: Performance Monitoring")
    logger.info("=" * 50)

    chief = ChiefAIAgent()
    await chief.start()

    mcp_server = BusinessToolsServer()
    await mcp_server.start()

    try:
        # Get current performance metrics
        logger.info("Analyzing current performance metrics...")

        performance_data = {
            "agent_metrics": {
                "active_agents": 1,
                "avg_response_time": "1.8s",
                "task_completion_rate": 0.94,
                "error_rate": 0.02,
            },
            "business_metrics": await mcp_server.call_tool(
                "get_business_metrics", {"metric_type": "operational"}
            ),
            "system_health": {
                "database_connections": 5,
                "memory_usage": "68%",
                "cpu_usage": "23%",
            },
        }

        # Ask Chief AI Agent for performance analysis
        performance_prompt = f"""
        As Chief AI Agent, analyze our current performance metrics and provide optimization recommendations.

        Current Performance Data:
        {json.dumps(performance_data, indent=2)}

        Please provide:
        1. Performance assessment (strengths and areas for improvement)
        2. Optimization recommendations
        3. Resource scaling suggestions
        4. Monitoring alerts to implement
        5. Performance targets for next quarter

        Focus on actionable improvements that can enhance system reliability and efficiency.
        """

        logger.info("Requesting performance analysis...")
        performance_analysis = await chief.think(performance_prompt)

        logger.info("Performance Analysis Complete")
        logger.info("=" * 30)
        logger.info(performance_analysis)

        # Save performance report
        report_file = project_root / "performance_report.md"
        with open(report_file, "w") as f:
            f.write(f"# ELF Automations Performance Report\n\n")
            f.write(f"Generated by Chief AI Agent\n\n")
            f.write(
                f"## Performance Data\n\n```json\n{json.dumps(performance_data, indent=2)}\n```\n\n"
            )
            f.write(f"## Analysis & Recommendations\n\n{performance_analysis}\n")

        logger.info(f"Performance report saved to {report_file}")

    except Exception as e:
        logger.error("Performance monitoring demo failed", error=str(e))

    await chief.stop()
    await mcp_server.stop()


async def main():
    """Main demo orchestrator."""
    logger.info("üöÄ ELF Automations Full System Demo")
    logger.info("=" * 60)

    # Load environment
    load_dotenv()

    # Check prerequisites
    has_anthropic = bool(os.getenv("ANTHROPIC_API_KEY"))
    has_database = bool(os.getenv("DATABASE_URL"))

    if not has_anthropic:
        logger.error("ANTHROPIC_API_KEY required for full demo")
        return 1

    if not has_database:
        logger.warning("DATABASE_URL not set - some features may be limited")

    logger.info(
        "Prerequisites check complete",
        llm_available=has_anthropic,
        database_available=has_database,
    )

    try:
        # Run comprehensive demos
        await demo_llm_powered_strategic_planning()
        await asyncio.sleep(2)  # Brief pause between demos

        if has_database:
            await demo_mcp_business_intelligence()
            await asyncio.sleep(2)

            await demo_agent_coordination()
            await asyncio.sleep(2)

            await demo_performance_monitoring()
        else:
            logger.info("Skipping database-dependent demos")

        logger.info("üéâ Full system demo completed successfully!")
        logger.info(
            "Check generated files: strategic_analysis.md, performance_report.md"
        )

        return 0

    except Exception as e:
        logger.error("Demo failed", error=str(e))
        return 1

    finally:
        # Cleanup
        await AgentRegistry.shutdown_all_agents()


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
